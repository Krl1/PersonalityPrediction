{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler, ConcatDataset\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from dataset import PersonalityDataset\n",
    "\n",
    "from models.mlp import MLPsimple\n",
    "from models.cnn8 import CNN8simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'BFD'\n",
    "dataset_type = 'rgb'\n",
    "\n",
    "batch_type = 'original' if dataset_type=='enc' else 'normalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer,train_accuracy):\n",
    "    train_loss, train_correct, train_correct_ocean = 0.0, 0, 0\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch[batch_type], batch['label']\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32, device=output.device)\n",
    "        loss = loss_fn(output.flatten(), labels.flatten())\n",
    "        train_accuracy(output, labels.to(torch.int64))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        predictions = torch.where(output>0, 1, 0)\n",
    "        train_correct += (predictions == labels.to(torch.int64)).sum().item()\n",
    "        train_correct_ocean += (predictions == labels.to(torch.int64)).sum(dim=0)\n",
    "\n",
    "    return train_loss, train_correct, train_correct_ocean\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn,val_accuracy):\n",
    "    valid_loss, val_correct, val_correct_ocean = 0.0, 0, 0\n",
    "    model.eval()\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch[batch_type], batch['label']\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32, device=output.device)\n",
    "        loss = loss_fn(output.flatten(),labels.flatten())\n",
    "        val_accuracy(output, labels.to(torch.int64))\n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "        predictions = torch.where(output>0, 1, 0)\n",
    "        val_correct += (predictions == labels.to(torch.int64)).sum().item()\n",
    "        val_correct_ocean += (predictions == labels.to(torch.int64)).sum(dim=0)\n",
    "\n",
    "    return valid_loss, val_correct, val_correct_ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocationConfig_data = f'data/{dataset_name}/{dataset_type}/'\n",
    "\n",
    "model_name = f'{dataset_name}_{dataset_type}'\n",
    "params = {}\n",
    "params['BFD_enc'] = {'batch_norm': True,'batch_size': 16,'dropout': 0.4,'lr': 0.001,'negative_slope': 0.05}\n",
    "params['BFD_gray'] = {'batch_norm': False,'batch_size': 16,'dropout': 0.4,'lr': 0.001,'negative_slope': 0.1}\n",
    "params['BFD_rgb'] = {'batch_norm': False,'batch_size': 8,'dropout': 0.0,'lr': 0.00005,'negative_slope': 0.02}\n",
    "params['ChaLearn_enc'] = {'batch_norm': False,'batch_size': 4,'dropout': 0.3,'lr': 0.001,'negative_slope': 0.1}\n",
    "params['ChaLearn_gray'] = {'batch_norm': True,'batch_size': 4,'dropout': 0.0,'lr': 0.001,'negative_slope': 0.01}\n",
    "params['ChaLearn_rgb'] = {'batch_norm': False,'batch_size': 8,'dropout': 0.0,'lr': 0.00005,'negative_slope': 0.1}\n",
    "\n",
    "epochs = {}\n",
    "epochs['BFD_enc'] = 10\n",
    "epochs['BFD_gray'] = 70\n",
    "epochs['BFD_rgb'] = 24\n",
    "epochs['ChaLearn_enc'] = 12\n",
    "epochs['ChaLearn_gray'] = 5\n",
    "epochs['ChaLearn_rgb'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: data/BFD/rgb/train/train.pickle\n",
      "file: data/BFD/rgb/test/test.pickle\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PersonalityDataset(Path(LocationConfig_data + 'train/'))\n",
    "test_dataset = PersonalityDataset(Path(LocationConfig_data + 'test/'))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "m=len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karol/miniconda3/envs/ur/lib/python3.8/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "<ipython-input-50-93c60e5f3382>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32, device=output.device)\n",
      "<ipython-input-50-93c60e5f3382>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32, device=output.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 1 | E:1/24 Tra Loss:0.666 Test Loss:0.708 Tra Acc 61.06% | 61.06% Test Acc 62.73% | 62.73%\n",
      "[53.03030014038086, 71.71717071533203, 71.96969604492188, 62.626258850097656, 45.9595947265625]\n",
      "F 1 | E:2/24 Tra Loss:0.640 Test Loss:0.677 Tra Acc 66.92% | 63.99% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n",
      "F 1 | E:3/24 Tra Loss:0.634 Test Loss:0.686 Tra Acc 66.92% | 64.97% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n",
      "F 1 | E:4/24 Tra Loss:0.635 Test Loss:0.667 Tra Acc 66.92% | 65.45% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n",
      "F 1 | E:5/24 Tra Loss:0.635 Test Loss:0.667 Tra Acc 66.92% | 65.75% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n",
      "F 1 | E:6/24 Tra Loss:0.632 Test Loss:0.671 Tra Acc 66.92% | 65.94% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n",
      "F 1 | E:7/24 Tra Loss:0.630 Test Loss:0.670 Tra Acc 66.92% | 66.08% Test Acc 62.73% | 62.73%\n",
      "[65.65657043457031, 71.71717071533203, 71.96969604492188, 62.626258850097656, 62.626258850097656]\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "    train_accuracy = Accuracy(threshold=0.0).cuda()\n",
    "    val_accuracy = Accuracy(threshold=0.0).cuda()\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    criterion = nn.BCEWithLogitsLoss()  \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=params[model_name]['batch_size'], sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=params[model_name]['batch_size'], sampler=test_sampler)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if dataset_type=='enc':\n",
    "        model = MLPsimple(**params[model_name])\n",
    "    else:\n",
    "        model = CNN8simple(data_type=dataset_type, dataset=dataset_name, **params[model_name])\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[model_name]['lr'])\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[],'train_acc_2':[],'test_acc_2':[],'train_acc_ocean':[],'test_acc_ocean':[]}\n",
    "\n",
    "    for epoch in range(epochs[model_name]):\n",
    "        train_loss, train_correct, train_correct_ocean = train_epoch(model,device,train_loader,criterion,optimizer,train_accuracy)\n",
    "        test_loss, test_correct, test_correct_ocean = valid_epoch(model,device,test_loader,criterion,val_accuracy)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / (len(train_loader.sampler) * 5) * 100\n",
    "        train_acc_2 = train_accuracy.compute() * 100\n",
    "        train_acc_ocean = train_correct_ocean / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / (len(test_loader.sampler) * 5) * 100\n",
    "        test_acc_2 = val_accuracy.compute() * 100\n",
    "        test_acc_ocean = test_correct_ocean / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"F {} | E:{}/{} Tra Loss:{:.3f} Test Loss:{:.3f} Tra Acc {:.2f}% | {:.2f}% Test Acc {:.2f}% | {:.2f}%\".format(\n",
    "            fold + 1,\n",
    "            epoch + 1,\n",
    "            epochs[model_name],\n",
    "            train_loss,\n",
    "            test_loss,\n",
    "            train_acc,\n",
    "            train_acc_2,\n",
    "            test_acc,\n",
    "            test_acc_2\n",
    "            ))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['train_acc_2'].append(train_acc_2.item())\n",
    "        history['test_acc_2'].append(test_acc_2.item())\n",
    "        print([t.item() for t in train_acc_ocean])\n",
    "        history['train_acc_ocean'].append([t.item() for t in train_acc_ocean])\n",
    "        history['test_acc_ocean'].append([t.item() for t in test_acc_ocean])\n",
    "\n",
    "    foldperf['fold{}'.format(fold+1)] = history  \n",
    "\n",
    "torch.save(model,f'model/k_cross/{dataset_name}_{dataset_type}.pt')\n",
    "a_file = open(f'results/{dataset_name}_{dataset_type}.pkl', 'wb')\n",
    "pickle.dump(foldperf, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ur",
   "language": "python",
   "name": "ur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
